{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 5px; height: 75px\">\n",
    "\n",
    "# The Caterpillar Effect : A Caterpillar Recognition Model\n",
    "Author: Sharifah Nurulhuda, DSI-SG-41 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01_Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use image transformations to augment our data in order to have a more robust dataset for modelling.\n",
    "\n",
    "We start off with 20 images of each caterpillar, which we then pass through this notebook to get 260 images each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for importing and exporting images\n",
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "#libraries for augmenting images\n",
    "import imgaug.augmenters as iaa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Function for Transforming the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `transforming_images` takes in an image and transforms the image in the following ways:\n",
    "\n",
    "1. Gamma Contrast\n",
    "2. Sigmoid Contrast\n",
    "3. Linear Contrast\n",
    "4. Cropping\n",
    "5. Elastic\n",
    "6. Polar\n",
    "7. Jigsaw\n",
    "8. Shear\n",
    "9. Adding Noise\n",
    "10. Rotation\n",
    "11. Horizontal Flip\n",
    "12. Vertical Flip\n",
    "\n",
    "The function returns a list of arrays `transformed_images_list` representing the orginal image and one from each transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforming_images(input_img):\n",
    "\n",
    "    # gamma contrast\n",
    "    contrast=iaa.GammaContrast((0.5, 2.0))\n",
    "    input_contrast = contrast.augment_image(input_img)\n",
    "    \n",
    "    # sigmoid contrast\n",
    "    contrast_sig = iaa.SigmoidContrast(gain=(5, 10), cutoff=(0.4, 0.6))\n",
    "    sigmoid_contrast = contrast_sig.augment_image(input_img)\n",
    "\n",
    "    # linear contrast\n",
    "    contrast_lin = iaa.LinearContrast((0.6, 0.4))\n",
    "    linear_contrast = contrast_lin.augment_image(input_img)\n",
    "\n",
    "    # cropping the image by 30%\n",
    "    crop1 = iaa.Crop(percent=(0, 0.3)) \n",
    "    input_crop1 = crop1.augment_image(input_img)\n",
    "    \n",
    "    # # applying an elastic transformation\n",
    "    # elastic = iaa.ElasticTransformation(alpha=60.0, sigma=4.0)\n",
    "    # input_elastic = elastic.augment_image(input_img)\n",
    "\n",
    "    # # warping image\n",
    "    # polar = iaa.WithPolarWarping(iaa.CropAndPad(percent=(-0.2, 0.7)))\n",
    "    # input_polar = polar.augment_image(input_img)\n",
    "\n",
    "    # # pixellising image to look like a jigsaw\n",
    "    # jigsaw = iaa.Jigsaw(nb_rows=20, nb_cols=15, max_steps=(3, 7))\n",
    "    # input_jigsaw = jigsaw.augment_image(input_img)\n",
    "\n",
    "    # shearing image by random amounts ranging from -40 to 40 degrees\n",
    "    shear = iaa.Affine(shear=(-40,40))\n",
    "    input_shear = shear.augment_image(input_img)\n",
    "\n",
    "    # adding noise to the image\n",
    "    noise = iaa.AdditiveGaussianNoise(10,40)\n",
    "    input_noise = noise.augment_image(input_img)\n",
    "\n",
    "    # rotation in degrees\n",
    "    rot1 = iaa.Affine(rotate=(-50,20))\n",
    "    input_rot1 = rot1.augment_image(input_img)\n",
    "\n",
    "    # horizontal Flip\n",
    "    hflip = iaa.Fliplr(p=1.0)\n",
    "    input_hf = hflip.augment_image(input_img)\n",
    "\n",
    "    # vertical Flip\n",
    "    vflip = iaa.Flipud(p=1.0) \n",
    "    input_vf = vflip.augment_image(input_img)\n",
    "\n",
    "    #creating a list of all the transformed images\n",
    "    transformed_images_list = [input_img, input_contrast, sigmoid_contrast, linear_contrast, input_crop1, input_hf, input_vf, input_rot1, input_noise, input_shear]     # input_polar, input_elastic, input_jigsaw\n",
    "\n",
    "    return transformed_images_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Images and Passing them through the Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the images are loaded into the notebook and passed through the function `transforming_images`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `os`, `cv2` and `PIL` libraries to access and save the images.\n",
    "\n",
    "First, the images are read from their respective folders. They are then passed through the function `transforming_images` and saved as an augmented image in their respective destination folders. These augmented images will then be used for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_list = ['chocolate_pansy', 'lime_caterpillar', 'painted_jezebel', 'plain_tiger']\n",
    "\n",
    "for folder in folder_list:\n",
    "\n",
    "    # defining directory where images are stored and where to call for images\n",
    "    image_folder = f'../data/caterpillars/{folder}'\n",
    "    image_files = os.listdir(image_folder)\n",
    "\n",
    "    # Read images using cv2.imread() and store them in a list\n",
    "    orig_images_list = []\n",
    "\n",
    "    for filename in image_files:\n",
    "        if not filename.startswith('.'):         #to ignore hidden files with '.' as first char in extension (e.g. '.DS_Store')\n",
    "            filepath = os.path.join(image_folder, filename)\n",
    "            image = cv2.imread(filepath)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)          #change colour scheme from bgr (os default) to rgb for saving\n",
    "            if image is not None:\n",
    "                orig_images_list.append(image)\n",
    "\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    destination_folder = f'../data/augmented/{folder}'\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "    # looping through the list of original images for transforming, naming and saving image\n",
    "\n",
    "    i=0                 #setting i = 0 at the start, so that all filenames will be unique\n",
    "\n",
    "    for image in orig_images_list:\n",
    "\n",
    "        transformed_list = transforming_images(image)\n",
    "\n",
    "        for transformed_image in transformed_list:\n",
    "            \n",
    "            # Convert each NumPy array in the list to a PIL Image object\n",
    "            image_pil = Image.fromarray(transformed_image)\n",
    "\n",
    "            # Save each image with a filename in the destination folder\n",
    "            filename = os.path.join(destination_folder, f'aug_{folder}_{i}.jpg')\n",
    "            image_pil.save(filename)\n",
    "\n",
    "            # adding one to i at each loop to change the filename accordingly\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Augmented Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our set of images to be used for modelling. \n",
    "\n",
    "They are stored in the following path: \n",
    "\n",
    "|Species|Destination Folder|Original Number of Images|Final Number of Augmented Images|\n",
    "|-----|-----|-----|-----|\n",
    "|Chocolate Pansy|`data/augmented/chocolate_pansy`|20|260|\n",
    "|Lime|`data/augmented/lime_caterpillar`|20|260|\n",
    "|Painted Jezebel|`data/augmented/painted_jezebel`|20|260|\n",
    "|Plain Tiger|`data/augmented/plain_tiger`|20|260|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
